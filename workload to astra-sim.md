# workload to astra-sim

## 思路：

首先，LLM可以看做多个transformer模型的堆叠，所以可以建立模型参数量与单次运算计算量的映射。

其次，如果考虑训练过程，可以指定一个平均的prefill长度，再指定一个平均的output长度，这样就可以算出kv_cache的长度。

为了处理kv_cache大小一直变化的问题，用batch_size乘平均长度，假设这就是通过调度可以得到的稳定状态的kv_cache_size。

晶圆级每个die会处理多个transformer block，只需要将所有这些block都融合成一个层即可。

训练过程的计算量可以看做推理过程的2倍。重计算保存的中间值可以在反向梯度传播到这里时，更快地准备好中间值。所以，应该每隔几层保存一些中间值。

用batch_size乘以层数再乘以（平均的prefill长度加output长度），即为全部中间值的参数量。假设每n个层保存一次中间值，且一共有N层，此处的最后一层离结尾的距离为k，则中间值大小为中间值平均长度乘以$(2k+N-n)*N/(2n)$

## 关于计算时间：

astra-sim的计算时间分为前向计算时间、前向通信类型、前向通信数据量、输入梯度计算时间、权重梯度计算时间、权重梯度通信类型、权重梯度通信数据量

### 前向计算时间：

首先使用workload文件中已有的模型得到计算量，计算量除以算力即为计算时间

计算访存时间的方法：

保存优先级：权重=>=kvcache>中间值

权重和kvcache的用法本质上是相同的。以下统称参数。

参数大小减去SRAM空间，即为保存在HBM上的参数量。如果参数大小超过HBM+SRAM容量，则需要保存到片下存储上。相当于有三部分参数，一部分在SRAM上，一部分在HBM上，一部分在片下。访存时间为这三部分到达片上时间的最长者。第一部分不考虑，一直在HBM上；第二部分大小除以HBM带宽即为第二部分读入时间。第三部分大小除以片下带宽即为第三部分读入时间。

中间值的保存优先级最低。如果HBM有空间就保存在HBM上，如果没有就保存在片下。访存时间最后要加上中间值写出的时间。在HBM上则用HBM带宽算访存时间，在片下则用片下带宽算访存时间。两部分都有则参照参数访存时间的算法。

前向计算时间为计算与访存时间两者的最大值。假设主频为1GHz，时间乘以主频即为cycle数。

### 前向通信类型

前向通信类型为ring

### 前向通信数据量

前向通信数据量为中间值大小。

### 输入梯度计算时间

假设每n个层保存一次中间值，且一共有N层，则计算时间为原计算时间乘以n除以N

### 权重梯度计算时间

同输入梯度计算时间

### 权重梯度通信类型

ring

### 权重梯度通信数据量

如果晶圆上只有一个模型，则为0

如果晶圆上有m个模型，即为当前数据量的m倍

